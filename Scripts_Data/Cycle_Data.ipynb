{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "180d6de9-b766-41c3-aeb3-a6447ab5c60d",
   "metadata": {},
   "source": [
    "# Data Wrangling of Santander Cycles Open Data\n",
    "\n",
    "For the #30DayMapChallenge I have used the Open Data for the Santander Cycles bike share scheme in London.\n",
    "Here, I have done some data manipulation from the data that I acquired from Transport for London Open Data.\n",
    "\n",
    "For this challenge, I did not use the real-time data from the API, but focused on the locations for bike points and some journeys data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd50d482-9bd4-4c14-b44c-dac2946e977c",
   "metadata": {},
   "source": [
    "## Fetching the Bike Points\n",
    "\n",
    "The data for bike points can be found from the [TfL Unified API](https://api.tfl.gov.uk/bikepoint).\n",
    "I have converted this file into a GeoJSON file for analysis.\n",
    "\n",
    "The data directory is not pushed to GitHub.\n",
    "Downloads the raw data into `DL_path`, and saves the points assigned by `points_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b23997a-0584-49f8-bf33-a6003ab29a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file from local\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Converts Bike Points into GeoJSON file\n",
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "# set paths\n",
    "DL_path = \"../Data/Cycles/DL_Data\"\n",
    "points_path = \"../Data/Cycles/Points\"\n",
    "points_fn = \"BikePoints.geojson\"\n",
    "\n",
    "# import json file from TfL Unified API if not already in local\n",
    "source_url = \"https://api.tfl.gov.uk/BikePoint\"\n",
    "\n",
    "if os.path.exists(os.path.join(DL_path, \"BikePoint.json\")):\n",
    "    print(\"Loading file from local\")\n",
    "    docks = json.load(open(os.path.join(DL_path, \"BikePoint.json\")))\n",
    "else:\n",
    "    print(f\"Download from {source_url}\") \n",
    "    with urllib.request.urlopen(source_url) as source:\n",
    "        docks = json.load(source)\n",
    "    # save to local\n",
    "    docks_DL_data = json.dumps(docks)\n",
    "    # creates saving directory if does not exist\n",
    "    if not os.path.exists(DL_path):\n",
    "        os.makedirs(DL_path)\n",
    "    # save json file\n",
    "    with open(os.path.join(DL_path, \"BikePoint.json\"), \"w\") as f:\n",
    "        f.write(docks_DL_data)\n",
    "\n",
    "# create output file\n",
    "output = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\" : []\n",
    "}\n",
    "\n",
    "# add docks data\n",
    "for d in docks:\n",
    "    for x in d[\"additionalProperties\"]:\n",
    "        if x[\"key\"] == \"TerminalName\":\n",
    "            id = x[\"value\"]\n",
    "    lat = d[\"lat\"]\n",
    "    lon = d[\"lon\"]\n",
    "    long_name = d[\"commonName\"]\n",
    "\n",
    "    #Separate area and specific port name\n",
    "    #Some have spaces before the comma, some do not\n",
    "    #\"Location , Area\" and \"Location, Area\" both exist\n",
    "    comma_spaced = d[\"commonName\"].rfind(\" , \")\n",
    "    comma_unspaced = d[\"commonName\"].rfind(\", \")\n",
    "    if comma_spaced != -1:\n",
    "        loc = d[\"commonName\"][:comma_spaced]\n",
    "        area = d[\"commonName\"][comma_spaced+3:]\n",
    "    elif comma_unspaced != -1:\n",
    "        loc = d[\"commonName\"][:comma_unspaced]\n",
    "        area = d[\"commonName\"][comma_unspaced+2:]\n",
    "    else:\n",
    "        loc = \"\"\n",
    "        area = \"\"        \n",
    "    for x in d[\"additionalProperties\"]:\n",
    "        if x[\"key\"] == \"NbDocks\":\n",
    "            docks = x[\"value\"]\n",
    "\n",
    "    # GeoJSON features\n",
    "    port = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [lon, lat]\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"id\": id,\n",
    "            \"name\": long_name,\n",
    "            \"location\": loc,\n",
    "            \"area\": area,\n",
    "            \"ports\": docks,\n",
    "        },\n",
    "    }\n",
    "    output[\"features\"].append(port)\n",
    "\n",
    "# create output\n",
    "docks_geojson = json.dumps(output)\n",
    "\n",
    "# creates saving directory if does not exist\n",
    "if not os.path.exists(points_path):\n",
    "    os.makedirs(points_path)\n",
    "\n",
    "# save json file\n",
    "with open(os.path.join(points_path, points_fn), \"w\") as f:\n",
    "    f.write(docks_geojson)\n",
    "print(\"done\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674146f-e155-4e80-83ad-645c2af239cd",
   "metadata": {},
   "source": [
    "## Fetching the Journeys for analysis\n",
    "\n",
    "Now, I have taken the journey data from TfL open data as well. Here, I took the first 1,000 lines from the latest data available, just so that I can plot on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "647c6ab0-8bf1-4631-be31-da2cd6edf544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from local\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Converts journeys into geometry\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "# number of journeys to stop at\n",
    "stop_count = 0\n",
    "\n",
    "DL_path = \"../Data/Cycles/DL_Data\"\n",
    "points_path = \"../Data/Cycles/Points\"\n",
    "points_fn = \"BikePoints.geojson\"\n",
    "journeys_path = \"../Data/Cycles/Journeys\"\n",
    "journeys_fn = \"journeys_\" + str(stop_count) + \".geojson\"\n",
    "\n",
    "# load docks\n",
    "docks_geojson = json.load(open(os.path.join(points_path, points_fn)))\n",
    "\n",
    "# output file\n",
    "journeys = {\n",
    "    \"type\": \"featureCollection\",\n",
    "    \"features\": []\n",
    "}\n",
    "\n",
    "# download and open csv files\n",
    "# source: https://cycling.data.tfl.gov.uk/usage-stats/374JourneyDataExtract12Jun2023-18Jun2023.csv\n",
    "journeys_source = \"https://cycling.data.tfl.gov.uk/usage-stats/374JourneyDataExtract12Jun2023-18Jun2023.csv\"\n",
    "journeys_DL_fn = \"374JourneyDataExtract12Jun2023-18Jun2023.csv\"\n",
    "\n",
    "# check and download if not existent\n",
    "if os.path.exists(os.path.join(DL_path, journeys_DL_fn)):\n",
    "    print(\"Load from local\")\n",
    "else:\n",
    "    print(\"Downloading file\")\n",
    "    response = urllib.request.urlopen(journeys_source)\n",
    "    journeys_DLdata = response.read().decode('UTF-8')\n",
    "    \n",
    "    with open(os.path.join(DL_path, journeys_DL_fn),w) as f:\n",
    "        f.write(journeys_DLdata)\n",
    "\n",
    "# load csv file\n",
    "with open(os.path.join(DL_path, journeys_DL_fn)) as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    count = 0\n",
    "    for row in csv_reader:\n",
    "        # get variables\n",
    "        rental_id = int(row[\"Number\"])\n",
    "        duration = int(row[\"Total duration (ms)\"])\n",
    "        bike_id = int(row[\"Bike number\"])\n",
    "        type = str(row[\"Bike model\"])\n",
    "        if row[\"End station number\"] != \"\":\n",
    "            end_id = str(row[\"End station number\"])\n",
    "        start_id = str(row[\"Start station number\"])\n",
    "        if row[\"End station\"] != \"\":\n",
    "            end_st = str(row[\"End station\"])\n",
    "        start_st = str(row[\"Start station\"])\n",
    "    \n",
    "        # get coordinates for start / end\n",
    "        start_coord = None\n",
    "        end_coord = None\n",
    "        for ds in output[\"features\"]:\n",
    "            if ds[\"properties\"][\"name\"] == start_st:\n",
    "    #            if ds[\"properties\"][\"id\"] == start_id:\n",
    "                start_coord = ds[\"geometry\"][\"coordinates\"]\n",
    "            if ds[\"properties\"][\"name\"] == end_st:\n",
    "    #            if ds[\"properties\"][\"id\"] == end_id:\n",
    "                end_coord = ds[\"geometry\"][\"coordinates\"]\n",
    "                \n",
    "        # outputs\n",
    "        journey = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"LineString\",\n",
    "                \"coordinates\": [start_coord, end_coord]\n",
    "            },\n",
    "            \"properties\": {\n",
    "                \"rental_id\": rental_id,\n",
    "                \"bike_id\": bike_id,\n",
    "                \"type\": type,\n",
    "                \"start_id\": start_id,\n",
    "                \"start_name\": start_st,\n",
    "                \"end_id\": end_id,\n",
    "                \"end_name\": end_st, \n",
    "                \"duration\": duration\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        journeys[\"features\"].append(journey)\n",
    "    \n",
    "        # stop at maximum\n",
    "        count += 1\n",
    "        if count == stop_count:\n",
    "            break\n",
    "\n",
    "\n",
    "journeys_geojson = json.dumps(journeys)\n",
    "\n",
    "# creates saving directory if does not exist\n",
    "if not os.path.exists(journeys_path):\n",
    "    os.makedirs(journeys_path)\n",
    "\n",
    "# save file\n",
    "with open(os.path.join(journeys_path, journeys_fn), \"w\") as f:\n",
    "    f.write(journeys_geojson)\n",
    "print(\"done\")\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
